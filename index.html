<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>The Shea Blog</title>
  <style>
    html, body { margin: 0; padding: 0; background: #f4f1ea; color: #222; font-family: Georgia, 'Times New Roman', Times, serif; line-height: 1.7; }
    a { color: #06c; text-decoration: underline; }
    a:visited { color: #551a8b; }
    .wrap { max-width: 760px; margin: 0 auto; padding: 24px 16px; }
    header { border: 1px solid #c9c3b8; background: #fffefa; padding: 24px; margin-bottom: 20px; }
    .site-title { font-size: 32px; margin: 0 0 6px; }
    nav { padding: 12px 0; border-top: 1px solid #e0dbcf; }
    nav button.tab { border: 0; background: transparent; padding: 10px 12px; margin-right: 8px; font: inherit; color: #06c; text-decoration: underline; cursor: pointer; }
    nav [aria-selected='true'] { color: #111; text-decoration: none; }
    main { background: #fff; border: 1px solid #d9d2c4; padding: 32px; margin-top: 20px; }
    .card { background:#fff; border: 1px solid #e6dfd2; padding: 32px; margin: 22px 0; }
    article h2 { font-size: 22px; margin-top: 0; }
    p { margin: 16px 0; }
    footer { border: 1px solid #c9c3b8; padding: 16px 20px; color: #555; background: #fffefa; margin-top: 20px; }
    [role='tabpanel'] { opacity: 0; visibility: hidden; height: 0; overflow: hidden; transition: opacity .3s ease, transform .3s ease; transform: translateY(6px); }
    [role='tabpanel'].active { opacity: 1; visibility: visible; height: auto; overflow: visible; transform: translateY(0); }
  </style>
</head>
<body>
  <div class="wrap">
    <header>
      <h1 class="site-title">The Shea Blog</h1>
      <div class="small">An ENC 1102 research blog on technology and human connection</div>
      <nav role="tablist" aria-label="Site tabs">
        <button class="tab" role="tab" aria-selected="true" aria-controls="draft2" id="tab-draft2">Argument (Draft 2)</button>
        <button class="tab" role="tab" aria-selected="false" aria-controls="draft1" id="tab-draft1">Argument (Draft 1)</button>
        <button class="tab" role="tab" aria-selected="false" aria-controls="works" id="tab-works">Works Cited</button>
        <button class="tab" role="tab" aria-selected="false" aria-controls="reflection" id="tab-reflection">Reflection</button>
      </nav>
    </header>

    <main>
      <!-- Draft 2 tab -->
      <section id="draft2" role="tabpanel" class="active" aria-labelledby="tab-draft2">
        <div class="card">
          <article>
            <h2>How reliance on AI shapes human connection (Draft 2)</h2>
            <div class="meta">By Brennan Shea. November 12, 2025.</div>
            <p>I use artificial intelligence every day, and it now drafts emails, plans tasks, and finds patterns in data that used to take me hours. These tools feel normal. The deeper question is how this reliance changes how people relate to one another. AI can lift productivity and widen access, but dependence can weaken human connection. The aim is measured use. Within the next year, schools, workplaces, and public agencies should label AI-assisted work, limit undisclosed automation in judgments, and require human review for high-stakes decisions.</p>
            <p>To begin with, the appeal is practical. People use AI to finish repetitive work quickly with fewer errors. It drafts notes, summarizes sources, and catches grammar problems. This saves time and frustration. Lawson reports similar gains, including better communication and creative support (Lawson). In my experience, using AI to outline schedules and build rough drafts frees attention for harder thinking and better conversations. Efficiency is real. It is one of the technology’s strongest benefits.</p>
            <p>At the same time, public benefits exist. In Southeast Asia, machine learning has improved weather prediction, forest monitoring, and waste management (Board). These results lead some to claim that rapid rollout proves social value. That gain matters. Yet scale without disclosure and oversight can hide risks, which undermines trust and makes later correction harder.</p>
            <p>Even so, serious ethical issues remain. The European Parliamentary Research Service warns that unregulated AI increases surveillance, bias, and privacy loss (European Parliamentary Research Service). When organizations automate decisions, small biases can widen into inequality. People who feel watched speak less and create less. A tool meant to empower can erode trust. Without guardrails, the systems that should connect us can divide us.</p>
            <p>Beyond ethics, there is a risk to critical thinking. Students who use chatbots for quick answers lose practice in analysis. Professionals who rely on assistants for feedback lose practice in empathy. Russell and Norvig note that intelligent reasoning depends on context, something machines still struggle to grasp (Russell and Norvig). If people outsource too much judgment, they lose skills that make human decisions valuable.</p>
            <p>Related to this, information quality also matters. Large models can produce fluent but unreliable text. They can mimic understanding while repeating bias and error. The result is polished writing without accuracy. When readers cannot tell truth from imitation, civic understanding suffers.</p>
            <p>To be clear, technology is not the only cause. Vincent argues that human priorities shape outcomes as much as code (Vincent). A meeting becomes shallow when leaders value speed over care. A class discussion loses meaning when students choose convenience over curiosity. Design and use are inseparable. Developers and users share responsibility for making tools serve human well-being.</p>
            <p>Given these tensions, privacy needs protection. Smart governance should require transparency, data minimization, and human oversight. Governments and companies should restrict unnecessary data collection and enforce fairness audits. Sensible regulation does not block progress. It makes innovation safer and more sustainable. These standards keep AI anchored to human dignity.</p>
            <p>Turning to practice, daily habits can preserve connection. Teams should reserve time for live problem solving, debate, and mentorship. Students should draft without AI, then use it for revision with a short process note that explains how. These habits protect creativity and empathy. Workplaces and classrooms thrive when dialogue, not automation, drives the hardest parts of the work.</p>
            <p>Critics worry that guardrails will slow innovation and create disadvantage. That fear is understandable in fields where speed stands in for progress. But trust is also an economic asset. If people understand how systems work, what data they use, and how to challenge outcomes, adoption gets easier, not harder. Responsible process reduces backlash and rework. Over time, it saves time.</p>
            <p>Education offers a clear example of balanced use. In classes that permit AI, clear norms reduce confusion and stress. Students can use assistants to brainstorm or check grammar, but they still write the core analysis. A short statement at the end of each submission can explain what the tool did, what the student did, and where judgment came from. That note turns a hidden shortcut into a visible choice. It also gives teachers a better view of process, which improves instruction.</p>
            <p>The workplace has parallel needs. Treat AI like a junior collaborator, helpful and fast, but never the final voice. Leaders can schedule regular human-only sessions for brainstorming and retrospectives. In those moments, people practice listening and argument without automatic suggestions. The contrast is healthy. It reminds teams that their value lies in insight and care, not throughput.</p>
            <p>Stepping back, culture shapes outcomes. Tools do not decide whether a community values speed over understanding or numbers over nuance. People do. When leaders choose metrics that treat conversation as waste, relationships thin out. When institutions reward reflection, people make time for it. The same technology can support either outcome. The difference is not the code, but the priorities around it.</p>
            <p>Equity also matters. If only well-resourced schools and workplaces can afford thoughtful guardrails, the benefits of AI will cluster with privilege while risks concentrate elsewhere. Shared standards for disclosure and review reduce the chance of a two-tier system in which some people get human attention and others get automated indifference.</p>
            <p>All told, AI should not stay in a lab. The promise is real, faster access to expertise, more consistent services, and new ways to learn and create. The challenge is to pursue those gains without draining the human contact that gives work and learning their meaning. In practice, write policies that are short, clear, and lived. Treat labels and process notes as habits, not hurdles. Honor slowness when speed would break trust.</p>
            <p>In the end, the question is not whether AI helps or harms. The question is how we choose to use it. AI can expand knowledge, simplify tasks, and improve services. It can also dull empathy, spread bias, and narrow curiosity if left unchecked. The future depends on our willingness to slow down, label help, and stay accountable. Pair efficiency with ethics, and curiosity with care, so AI supports, not replaces, the human connection that defines us.</p>
            <p>My habits reflect this approach. I still use AI for outlines and checks, but I pause before accepting the first draft. I ask whether the sentence sounds like me, whether the claim has a source I can read, and whether the suggestion would land well with the person on the other side. That pause takes a minute. It often saves an apology later. It feels like the difference between sending words and sending attention.</p>
          </article>
        </div>
      </section>

      <!-- Draft 1 tab -->
      <section id="draft1" role="tabpanel" aria-labelledby="tab-draft1">
        <div class="card">
          <article>
            <h2>How reliance on AI shapes human connection (Draft 1)</h2>
            <div class="meta">By Brennan Shea. November 3, 2025.</div>
            <p>I use artificial intelligence every day. It helps me draft emails, plan tasks, and find patterns in data. These tools feel natural now. Yet as their use expands, I often wonder how this growing reliance changes the way people relate to one another. Artificial intelligence can lift productivity and widen access, but unchecked dependence may weaken real human connection. The goal is not to reject AI but to manage its place responsibly in modern life.</p>
            <p>To understand the appeal of AI, it helps to look at its practical benefits. Many users rely on AI to complete repetitive tasks quickly and accurately. It drafts notes, summarizes information, and corrects grammar errors, saving people both time and frustration. Lawson highlights these effects, noting how AI enhances communication and creativity for everyday users (Lawson). From my experience, using AI to organize schedules and generate drafts frees mental space for deeper thought and more meaningful conversation. This efficiency represents one of the technology’s greatest strengths.</p>
            <p>These personal advantages also extend to public good. In Southeast Asia, machine learning has improved weather prediction, forest monitoring, and waste management. Board documents these examples, showing that while infrastructure limits remain, the results prove promising (Board). Projects like these demonstrate how AI can serve as a global tool for safety, sustainability, and innovation. When systems prevent harm or protect natural resources, they validate their role as an ally to human progress.</p>
            <p>However, these benefits are paired with serious ethical concerns. The European Parliamentary Research Service warns that unregulated AI use increases surveillance, bias, and privacy loss. As organizations automate decision-making, small biases can scale into widespread inequality. People who feel monitored may avoid open dialogue or creativity (European Parliamentary Research Service). In this way, technology that should empower users can instead suppress trust. Without oversight, the systems meant to connect us could divide us further.</p>
            <p>Beyond issues of privacy, dependence on AI can erode critical thinking. Students who turn to chatbots for quick answers lose practice in analysis. Professionals who use digital assistants to write feedback risk losing empathy. Russell and Norvig explain that intelligent reasoning depends heavily on context, something machines still struggle to grasp (Russell and Norvig). When people outsource judgment to AI, they slowly lose the very skills that make human decision-making valuable.</p>
            <p>Some experts argue this erosion extends to information itself. Bender and colleagues describe the “stochastic parrots” problem, where language models generate fluent but unreliable text (Bender et al.). While these systems mimic understanding, they often reproduce existing biases or errors. The result is polished writing without accuracy. When audiences cannot tell truth from imitation, civic understanding weakens. This confusion threatens democracy as much as individual learning.</p>
            <p>Social scientists also warn that AI can widen emotional distance. Turkle observes that people increasingly substitute digital conversation for genuine connection (Turkle). AI could accelerate this by managing emotional exchanges on our behalf. For example, users can ask a chatbot to write apologies, compliments, or condolences. The words may be polite, but they lack the personal vulnerability that builds trust. Over time, emotional outsourcing could dull empathy and make real relationships harder to maintain.</p>
            <p>Still, some believe that technology itself is not to blame. Vincent argues that human priorities shape AI outcomes, not the algorithms alone (Vincent). A meeting becomes shallow only when leaders value speed over care. A class discussion loses meaning only when students choose convenience over curiosity. This argument reminds us that design and use are inseparable. Developers and users share equal responsibility for ensuring that tools serve human well-being.</p>
            <p>Protecting privacy is equally crucial. The OECD emphasizes transparency and human oversight as essential safeguards (OECD). Governments and corporations must restrict unnecessary data collection and enforce fairness audits for algorithms. Responsible regulation does not limit progress; it ensures that innovation remains ethical and sustainable. These standards keep AI grounded in respect for human dignity.</p>
            <p>Just as systems need oversight, people need practice. Teams should reserve time for live problem-solving, debate, and mentorship. Students should write first drafts without AI before using it for revision. These steps preserve creativity and empathy. In both workplaces and classrooms, collaboration grows stronger when people rely on dialogue, not automation, to solve problems.</p>
            <p>Education shows how balance can succeed. Teachers can integrate AI as a brainstorming aid while reinforcing original thought. Asking students to explain how AI shaped their work builds accountability and reflection. These habits teach digital ethics and reinforce the value of authenticity in writing and discussion. When guided carefully, AI becomes a tool for growth, not avoidance.</p>
            <p>Public institutions face similar challenges. They can apply AI to improve public safety, manage infrastructure, and expand access to information. Yet human oversight must remain central. Publishing clear reports about how AI systems operate and inviting citizen feedback promote transparency. Treating the public as collaborators rather than subjects builds civic trust and ensures that innovation aligns with shared values.</p>
            <p>In the end, the question is not whether AI helps or harms but how humans choose to use it. Artificial intelligence magnifies both our strengths and our weaknesses. It can expand knowledge, streamline systems, and improve lives. It can also reduce empathy, spread bias, and dull creativity if left unchecked. The future depends on our willingness to slow down, reflect, and stay accountable. By pairing efficiency with ethics, and curiosity with care, we can ensure that AI supports, not replaces, the human connection that defines us.</p>
          </article>
        </div>
      </section>

      <section id="works" role="tabpanel" aria-labelledby="tab-works">
        <div class="card">
          <h2>Works Cited</h2>
          <ol class="works">
            <li>Board, Jack. "AI in Southeast Asia: Machine Learning Offers New Solutions to Age-old Environmental Problems." Channel News Asia, 2024.</li>
            <li>European Parliamentary Research Service. <em>The Ethics of Artificial Intelligence: Issues and Initiatives</em>. European Parliament, 2020.</li>
            <li>Lawson, BriA’nna. "Enhancing Everyday Life: How AI is Revolutionizing Your Daily Experience." CEAMLS News, Morgan State University, 21 Nov. 2023.</li>
            <li>Russell, Stuart, and Peter Norvig. <em>Artificial Intelligence: A Modern Approach</em>. 4th ed., Pearson, 2021.</li>
            <li>Vincent, James. "The Problem with AI Isn’t Technology, it’s Humans." <em>The Verge</em>, 2023.</li>
            <li>Bender, Emily M., et al. "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big." <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>, 2021.</li>
            <li>OECD. <em>OECD Principles on Artificial Intelligence</em>. Organisation for Economic Co-operation and Development, 2019.</li>
            <li>Turkle, Sherry. <em>Alone Together: Why We Expect More from Technology and Less from Each Other</em>. Basic Books, 2011.</li>
          </ol>
        </div>
      </section>

      <section id="reflection" role="tabpanel" aria-labelledby="tab-reflection">
        <div class="card">
          <h2>Reflection</h2>
          <p>Writing this project taught me how to connect evidence, purpose, and audience into one sustained argument. At first, I saw research writing as formal and distant, but ENC 1102 helped me see it as a process of choice and clarity. I had to decide what claim mattered, why readers should care, and how sources could guide reasoning without taking control of it. My goal was to balance analysis and simplicity so that the essay could read like a conversation about real consequences. Revision played the biggest role in growth. Early drafts felt mechanical. Later ones focused more on cause and effect, tone, and smooth transitions. I also learned to cut vague language and choose verbs that show intent. Citing sources correctly built credibility and rhythm. More than anything, I learned to treat writing as an act of thinking out loud, where each paragraph tests an idea against evidence. This reflection represents how ENC 1102 changed my understanding of writing from a grade-driven task to a form of inquiry and expression. It is about learning to write with both discipline and curiosity, which are the same skills that make responsible research possible. Regarding AI, I have used models such as GPT-5 to overall ask for opinion on my work (how it can be objectively improved). In this sense, it helped me add context to my writing, due to my audience’s prior knowledge before reading the blog.</p>
        </div>
      </section>
    </main>

    <footer>
      <div>© 2025 Brennan Shea.</div>
    </footer>
  </div>

  <script>
    const tabs = document.querySelectorAll('[role="tab"]');
    const panels = document.querySelectorAll('[role="tabpanel"]');
    function activate(id) {
      panels.forEach(p => {
        const isTarget = p.id === id;
        p.classList.toggle('active', isTarget);
        p.setAttribute('aria-hidden', String(!isTarget));
      });
      tabs.forEach(t => t.setAttribute('aria-selected', String(t.getAttribute('aria-controls') === id)));
      history.replaceState(null, '', '#' + id);
    }
    tabs.forEach(t => t.addEventListener('click', () => activate(t.getAttribute('aria-controls'))));
    const hash = location.hash.replace('#','');
    if (hash && document.getElementById(hash)) activate(hash);
  </script>
</body>
</html>
